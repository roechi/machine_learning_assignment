{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Support Vector Machine for Credit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn as sk\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "\n",
    "def mean_score(text, scores):\n",
    "    return (str(text) + ' {0:.8f} (+/-{1:.5f})').format(np.mean(scores), sem(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_svm(train_size, svm, df, n_iter):\n",
    "    auc_scores = []\n",
    "    accs = []\n",
    "    for i in range(0, n_iter):\n",
    "        train, test = sk.cross_validation.train_test_split(df, train_size=train_size, random_state=1)\n",
    "        y = train['SeriousDlqin2yrs']\n",
    "        X = train.drop('SeriousDlqin2yrs', axis=1)\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "        y_test = test['SeriousDlqin2yrs']\n",
    "        X_test = test.drop('SeriousDlqin2yrs', 1)\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "        svm.fit(X, y)\n",
    "        auc_scores.append(sk.metrics.roc_auc_score(y_test, svm.predict_proba(X_test).T[1]))\n",
    "        accs.append(svm.score(X_test, y_test))\n",
    "    print(mean_score('roc auc score:', auc_scores))\n",
    "    print(mean_score('accuracy:', accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score: 0.68119558 (+/-0.00031)\n",
      "accuracy: 0.93310601 (+/-0.00000)\n"
     ]
    }
   ],
   "source": [
    "df_clean = pd.read_csv('./data/cs-train_clean.csv').drop('Unnamed: 0', axis=1)\n",
    "svc = SVC(kernel='rbf', C=1, gamma=0.001, probability=True)\n",
    "test_svm(0.01, svc, df_clean, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "while tweaking the parameters for svm, we noticed an increase of preciscion proportional to an increased number of training samples. However, processing 5% samples, already takes abaout 10 minutes on my machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyhow, this way of testing is not that efficient at all, we still don't know which params to use, to get a descent result. So we will try a GridSearch. We took the parameter range from a tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_grid_search(train_size, svc_params, df, n_iter):\n",
    "    auc_scores = []\n",
    "    accs = []\n",
    "    for i in range(0, n_iter):\n",
    "        train, test = sk.cross_validation.train_test_split(df, train_size=train_size, random_state=1)\n",
    "        X_train = train.drop('SeriousDlqin2yrs', axis=1)\n",
    "        y_train = train.SeriousDlqin2yrs \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        y_test = test['SeriousDlqin2yrs']\n",
    "        X_test = test.drop('SeriousDlqin2yrs', 1)\n",
    "        X_test = scaler.fit_transform(X_test)\n",
    "        gs_svc = GridSearchCV(SVC(), svc_params, cv = 3, n_jobs=-1)\n",
    "        gs_svc.fit(X_train, y_train)\n",
    "        scv=gs_svc.best_estimator_\n",
    "        svc.fit(X_train, y_train)\n",
    "        auc_scores.append(sk.metrics.roc_auc_score(y_test, svc.predict_proba(X_test).T[1]))\n",
    "        accs.append(svc.score(X_test, y_test))\n",
    "    print(mean_score('roc auc score:', auc_scores))\n",
    "    print(mean_score('accuracy:', accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_params = {\n",
    "    'C': np.logspace(-1, 2, 4),\n",
    "    'gamma': np.logspace(-4, 0, 5),\n",
    "    'probability': [True]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score: 0.68088391 (+/-0.00030)\n",
      "accuracy: 0.93310601 (+/-0.00000)\n"
     ]
    }
   ],
   "source": [
    "df_clean = pd.read_csv('./data/cs-train_clean.csv').drop('Unnamed: 0', axis=1)\n",
    "svm_grid_search(0.01, svc_params, df_clean, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Cropped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score: 0.49841584 (+/-0.01949)\n",
      "accuracy: 0.93050522 (+/-0.00000)\n"
     ]
    }
   ],
   "source": [
    "df_cropped = pd.read_csv('./data/cs-train_cropped.csv').drop('Unnamed: 0', axis=1)\n",
    "svm_grid_search(0.01, svc_params, df_cropped, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score: 0.66289212 (+/-0.00000)\n",
      "accuracy: 0.61334848 (+/-0.00000)\n"
     ]
    }
   ],
   "source": [
    "df_oversampled = pd.read_csv('./data/cs-train_oversampled.csv').drop('Unnamed: 0', axis=1)\n",
    "svm_grid_search(0.01, svc_params, df_oversampled, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc auc score: 0.72650176 (+/-0.00001)\n",
      "accuracy: 0.50634576 (+/-0.00000)\n"
     ]
    }
   ],
   "source": [
    "df_undersampled = pd.read_csv('./data/cs-train_undersampled.csv').drop('Unnamed: 0', axis=1)\n",
    "svm_grid_search(0.01, svc_params, df_undersampled, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
